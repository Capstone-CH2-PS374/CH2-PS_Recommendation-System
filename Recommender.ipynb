{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/argalusmp/CH2-PS_Recommendation-System/blob/V/Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY4aTHkiG5bL"
      },
      "source": [
        "[Collab](https://colab.research.google.com/drive/1d9l2-NXW5traKPQ0j-l4eZ2vSI0mEVvV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8nhDATdPwXe"
      },
      "source": [
        "# **Build Recommendation System with Content-Based Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5u2dta3QRWs"
      },
      "source": [
        "# Packages\n",
        "\n",
        "Import Packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
        "\n",
        "# Load Event dataset\n",
        "event_data = pd.read_csv(\"./events_dataset.csv\")\n",
        "\n",
        "event_df = pd.DataFrame(event_data)\n",
        "\n",
        "# Load User dataset\n",
        "user_data = pd.read_csv(\"./users_dataset.csv\")\n",
        "\n",
        "user_df = pd.DataFrame(user_data)\n",
        "\n",
        "# Preprocess data\n",
        "def preprocess_event_data(event_df):\n",
        "     # One-hot encode categorical variables\n",
        "    event_df = pd.get_dummies(event_df, columns=['Category', 'Location'])\n",
        "\n",
        "    # Split Qualifications into separate skills\n",
        "    event_df['Skills'] = event_df['Qualifications'].apply(lambda x: ' '.join(x.lower().split(',')) if pd.notnull(x) else '')\n",
        "    return event_df[list(event_df.columns[3:])]\n",
        "\n",
        "def preprocess_user_data(user_df):\n",
        "    # Convert categorical features to numerical representation\n",
        "\n",
        "    # Split Skills into separate skills\n",
        "    user_df['Skills'] = user_df['Skills'].apply(lambda x: ' '.join(x.lower().split(',')) if pd.notnull(x) else '')\n",
        "\n",
        "    return user_df[['Volunteer Name',  'Gender', 'Skills', 'Location', 'Type of Organization']]\n",
        "\n",
        "event_df = preprocess_event_data(event_df)\n",
        "user_df = preprocess_user_data(user_df)\n",
        "\n",
        "# Create a mapping for skills\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit(event_df['Skills'].explode().unique())\n",
        "\n",
        "# Transform event and user skills into binary vectors\n",
        "event_skills = pd.DataFrame(mlb.transform(event_df['Skills']), columns=mlb.classes_)\n",
        "user_skills = pd.DataFrame(mlb.transform(user_df['Skills']), columns=mlb.classes_)\n",
        "\n",
        "# Combine the binary vectors with the original dataframes\n",
        "event_df = pd.concat([event_df, event_skills], axis=1)\n",
        "user_df = pd.concat([user_df, user_skills], axis=1)\n",
        "\n",
        "# Drop the original 'Skills' column\n",
        "event_df.drop('Skills', axis=1, inplace=True)\n",
        "user_df.drop('Skills', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_fPbRQSskA62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the recommendation model\n",
        "def build_model():\n",
        "    # Input layers\n",
        "    event_input = Input(shape=(event_df.shape[1]-1,), name='event_input')\n",
        "    user_input = Input(shape=(user_df.shape[1]-1,), name='user_input')\n",
        "\n",
        "    # Embedding layers for event and user\n",
        "    event_embedding = Embedding(input_dim=2, output_dim=5, input_length=event_df.shape[1]-1)(event_input)\n",
        "    user_embedding = Embedding(input_dim=2, output_dim=5, input_length=user_df.shape[1]-1)(user_input)\n",
        "\n",
        "    # Flatten the embeddings\n",
        "    event_flatten = Flatten()(event_embedding)\n",
        "    user_flatten = Flatten()(user_embedding)\n",
        "\n",
        "    # Concatenate the flattened embeddings\n",
        "    concat = Concatenate()([event_flatten, user_flatten])\n",
        "\n",
        "    # Dense layers for the recommendation model\n",
        "    dense1 = Dense(128, activation='relu')(concat)\n",
        "    dense2 = Dense(64, activation='relu')(dense1)\n",
        "    output = Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = Model(inputs=[event_input, user_input], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V4S5iV-vmClv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_event_train, X_event_test, X_user_train, X_user_test, y_train, y_test = train_test_split(\n",
        "    event_df.drop('Event_id', axis=1).values,\n",
        "    user_df.drop('Volunteer Name', axis=1).values,\n",
        "    np.ones(event_df.shape[0]), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert data to NumPy arrays with appropriate data types\n",
        "X_event_train = np.asarray(X_event_train).astype(np.float32)\n",
        "X_event_test = np.asarray(X_event_test).astype(np.float32)\n",
        "X_user_train = np.asarray(X_user_train).astype(np.float32)\n",
        "X_user_test = np.asarray(X_user_test).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "y_test = np.asarray(y_test).astype(np.float32)\n",
        "\n",
        "# Build and train the model\n",
        "model = build_model()\n",
        "model.fit(x=[X_event_train, X_user_train], y=y_train, epochs=10, batch_size=32, validation_data=([X_event_test, X_user_test], y_test))\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict([event_df.drop('Event_id', axis=1).values, user_df.drop('Volunteer Name', axis=1).values])\n",
        "\n",
        "# Print the predictions\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "fYORV-PHl-KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqGtDqpdQgiz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gw06VeaRCOD"
      },
      "source": [
        "# Import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUo3-g3uRFqz"
      },
      "outputs": [],
      "source": [
        "user_dataset = pd.read_csv(\"./users_dataset.csv\")\n",
        "event_dataset= pd.read_csv(\"./events_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro1ezA7xF-c3"
      },
      "outputs": [],
      "source": [
        "df_user = pd.DataFrame(user_dataset)\n",
        "df_event = pd.DataFrame(event_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPlV_6I2TdkE",
        "outputId": "3c3d5242-2592-4dfa-b989-449b7bfa821c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2786\n",
            "2786\n"
          ]
        }
      ],
      "source": [
        "print(len(df_user))\n",
        "print(len(df_event))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbCb8aclGZC8"
      },
      "outputs": [],
      "source": [
        "skills_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "skills_encoded = skills_encoder.fit_transform(df_user[['Skills']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NybQAYiqJWK9"
      },
      "outputs": [],
      "source": [
        "location_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "location_encoded = location_encoder.fit_transform(df_event[['Location']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eAYvs3MJXLS"
      },
      "outputs": [],
      "source": [
        "# One-hot encoding untuk kategori acara\n",
        "category_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "category_encoded = category_encoder.fit_transform(df_event[['Category']])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(category_encoded)"
      ],
      "metadata": {
        "id": "rRYk6CclhJDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(event_matrix)"
      ],
      "metadata": {
        "id": "nWcKPZPfhtA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTkyHVPuJYEk"
      },
      "outputs": [],
      "source": [
        "# Bagi data menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_volunteer[['Skills', 'Location', 'Age']], df_volunteer['Target_Label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7KBW-TR_mX0"
      },
      "source": [
        "# Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnNdQnXePd4V"
      },
      "outputs": [],
      "source": [
        "all_data = pd.merge(user_dataset, event_dataset, how='cross')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv5LGlTTPpKd"
      },
      "outputs": [],
      "source": [
        "# Pisahkan data menjadi train dan test\n",
        "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8v2Jmrc_kVy"
      },
      "outputs": [],
      "source": [
        "# Preprocessing user data\n",
        "user_dataset['Skills'] = user_dataset['Skills'].str.lower()\n",
        "user_dataset['Availability'] = user_dataset['Availability'].str.lower()\n",
        "user_dataset['Location'] = user_dataset['Location'].str.lower()\n",
        "user_dataset['Type of Organization'] = user_dataset['Type of Organization'].str.lower()\n",
        "\n",
        "## Preprocessing event data\n",
        "event_dataset['Kualifikasi'] = event_dataset['Kualifikasi'].str.lower()\n",
        "event_dataset['Domisili'] = event_dataset['Domisili'].str.lower()\n",
        "event_dataset['Kategori'] = event_dataset['Kategori'].str.lower()\n",
        "event_dataset['Age'] = event_dataset['Age'].str.lower()\n",
        "\n",
        "\n",
        "## Memisahkan user skill menjadi beberapa kolom terpisah untuk one hot\n",
        "user_skills_split = user_dataset['Skills'].str.split(', ', expand=True)\n",
        "\n",
        "## Create one-hot encoding for user skills\n",
        "user_skills_one_hot = pd.get_dummies(user_skills_split, prefix='Skill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TS5IErcJUKv"
      },
      "outputs": [],
      "source": [
        "## Menggabungkan dataset\n",
        "merged_data = pd.merge(user_dataset, event_dataset, how='cross')\n",
        "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
        "\n",
        "## Create one-hot encoding for user and event data\n",
        "user_one_hot = pd.get_dummies(merged_data[['Age_x', 'Availability', 'Location', 'Type of Organization']], prefix='User')\n",
        "event_one_hot = pd.get_dummies(merged_data[[ 'Kategori', 'Age_y','Domisili']], prefix='Event')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH_nBWffvpu1"
      },
      "outputs": [],
      "source": [
        "## Check Display\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "event_one_hot\n",
        "#user_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XC8QVVpmc39b"
      },
      "outputs": [],
      "source": [
        "## Merge Onehot encoding with data user\n",
        "user_data_encode = pd.concat([user_one_hot, user_skills_one_hot], axis=1)\n",
        "user_data_encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ckh299YzcEtD"
      },
      "outputs": [],
      "source": [
        "## Memisahkan event kualifikasi menjadi beberapa kolom terpisah untuk one hot\n",
        "event_kualifikasi_split = event_dataset['Kualifikasi'].str.split(', ', expand=True)\n",
        "\n",
        "## Create one-hot encoding for kualifikasi\n",
        "event_kualifikasi_one_hot = pd.get_dummies(event_kualifikasi_split, prefix='Kualifikasi')\n",
        "\n",
        "## Merge Kualifikasi with dataset event after one-hot kualifikasi\n",
        "event_data_encode = pd.concat([event_one_hot, event_kualifikasi_one_hot], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBS3Q1O7xzlM"
      },
      "outputs": [],
      "source": [
        "## Check event encode display\n",
        "event_data_encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11LOccTgMewM"
      },
      "outputs": [],
      "source": [
        "print(user_data_encode.isnull().sum())\n",
        "print(event_data_encode.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzqxGqliWLJm"
      },
      "outputs": [],
      "source": [
        "## For set Y to target\n",
        "#target_columns = ['Kualifikasi_kualifikasi1', 'Kualifikasi_kualifikasi2', ...]\n",
        "#X_train, X_test, y_train, y_test = train_test_split(user_data_encode, event_data_encode[target_columns], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "## Train-test split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8lnGwUC_71g"
      },
      "source": [
        "Nyoba proses nilai umur\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "###Pemrosesan Data Umur\n",
        "def process_age(value):\n",
        "    if '-' in str(value):  # Jika nilai adalah rentang umur\n",
        "        age_range = value.split('-')\n",
        "        return (int(age_range[0]) + int(age_range[1])) / 2\n",
        "    elif isinstance(value, int):  # Jika nilai adalah umur tunggal dan sudah integer\n",
        "        return value\n",
        "    else:\n",
        "        # Penanganan lainnya\n",
        "        return None\n",
        "\n",
        "\n",
        "event_dataset['Age'] = event_dataset['Age'].apply(process_age)\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYnicmNlW8VO"
      },
      "source": [
        "# Try and Try and Try"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEbsj81dU3a9"
      },
      "source": [
        "# Pusing NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXAFNyBjU25g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Baca dataset\n",
        "user_dataset = pd.read_csv(\"./users_dataset.csv\")\n",
        "event_dataset = pd.read_csv(\"./events_dataset.csv\")\n",
        "\n",
        "# Preprocessing user data\n",
        "user_dataset['Skills'] = user_dataset['Skills'].str.lower()\n",
        "user_dataset['Location'] = user_dataset['Location'].str.lower()\n",
        "user_dataset['Type of Organization'] = user_dataset['Type of Organization'].str.lower()\n",
        "\n",
        "# Preprocessing event data\n",
        "event_dataset['Qualifications'] = event_dataset['Qualifications'].str.lower()\n",
        "event_dataset['Location'] = event_dataset['Location'].str.lower()\n",
        "event_dataset['Category'] = event_dataset['Category'].str.lower()\n",
        "\n",
        "# Gabungkan data\n",
        "full_data = pd.merge(user_dataset, event_dataset, how='cross')\n",
        "\n",
        "# Pisahkan data menjadi train dan test\n",
        "train_data, test_data = train_test_split(full_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encoding dan penggabungan data\n",
        "user_skills_split = user_dataset['Skills'].str.split(', ', expand=True)\n",
        "user_skills_one_hot = pd.get_dummies(user_skills_split, prefix='Skill')\n",
        "\n",
        "user_one_hot_train = pd.get_dummies(train_data[[ 'Skills', 'Location', 'Type of Organization']], prefix='User')\n",
        "event_one_hot_train = pd.get_dummies(train_data[['Category', 'Location', 'Qualifications']], prefix='Event')\n",
        "event_kualifikasi_one_hot_train = pd.get_dummies(train_data['Qualifications'].str.split(', ', expand=True), prefix='Qualifications')\n",
        "\n",
        "train_data_encode = pd.concat([user_one_hot_train, user_skills_one_hot, event_one_hot_train, event_kualifikasi_one_hot_train], axis=1)\n",
        "\n",
        "# Normalisasi data\n",
        "scaler = StandardScaler()\n",
        "train_data_normalize = scaler.fit_transform(train_data_encode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCD999T_WEyd"
      },
      "outputs": [],
      "source": [
        "train_data_normalize = np.nan_to_num(train_data_normalize, nan=np.nanmean(train_data_normalize, axis=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb4H06KBWNn4",
        "outputId": "793a47bb-0821-4018-d651-6964acb0d6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "print(np.isnan(train_data_normalize).any())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG_jvJo3VTF1"
      },
      "outputs": [],
      "source": [
        "# Hitung similarity matrix menggunakan cosine similarity\n",
        "similarity_matrix = cosine_similarity(train_data_normalize, train_data_normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-V7Xo8FWZsI"
      },
      "outputs": [],
      "source": [
        "print(f\"Cosine Similarity: {similarity_matrix[0][0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmsNhHe3ZkU2"
      },
      "source": [
        "# This one using vectorize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwIcbYxmW0lV",
        "outputId": "8dfa27fa-d228-495e-eeb7-c01c4fc91e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2592    E_2593\n",
            "2683    E_2684\n",
            "2723    E_2724\n",
            "2735    E_2736\n",
            "2744    E_2745\n",
            "2531    E_2532\n",
            "2659    E_2660\n",
            "2668    E_2669\n",
            "2776    E_2777\n",
            "2399    E_2400\n",
            "Name: Event_id, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "\n",
        "# Load the datasets\n",
        "user_df = pd.read_csv('users_dataset.csv')\n",
        "event_df = pd.read_csv('events_dataset.csv')\n",
        "\n",
        "# Preprocessing\n",
        "user_df['Skills'] = user_df['Skills'].apply(lambda x: ' '.join(x.lower().split(', ')) if pd.notnull(x) else '')\n",
        "event_df['Qualifications'] = event_df['Qualifications'].apply(lambda x: ' '.join(x.lower().split(', ')) if pd.notnull(x) else '')\n",
        "\n",
        "# Vectorize the skills and qualifications\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "user_matrix = vectorizer.fit_transform(user_df['Skills'])\n",
        "event_matrix = vectorizer.transform(event_df['Qualifications'])\n",
        "\n",
        "# Compute the cosine similarity\n",
        "cosine_sim = linear_kernel(user_matrix, event_matrix)\n",
        "\n",
        "# Function to get recommendations\n",
        "def get_recommendations(user_index, cosine_sim=cosine_sim):\n",
        "    # Get the pairwsie similarity scores of all events for that user\n",
        "    sim_scores = list(enumerate(cosine_sim[user_index]))\n",
        "\n",
        "    # Sort the events based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the 10 most similar events\n",
        "    sim_scores = sim_scores[0:10]\n",
        "\n",
        "    # Get the event indices\n",
        "    event_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top 10 most similar events\n",
        "    return event_df['Event_id'].iloc[event_indices]\n",
        "\n",
        "# Test the system relation user 1 (index 0) to event\n",
        "print(get_recommendations(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This one using Tokenizer NLP\n"
      ],
      "metadata": {
        "id": "Jzx6isyunkAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the datasets\n",
        "user_df = pd.read_csv('users_dataset.csv')\n",
        "event_df = pd.read_csv('events_dataset.csv')\n",
        "\n",
        "# Preprocessing\n",
        "user_df['Skills'] = user_df['Skills'].apply(lambda x: ' '.join(x.lower().split(', ')) if pd.notnull(x) else '')\n",
        "event_df['Qualifications'] = event_df['Qualifications'].apply(lambda x: ' '.join(x.lower().split(', ')) if pd.notnull(x) else '')\n",
        "\n",
        "# Tokenize the skills and qualifications\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(pd.concat([user_df['Skills'], event_df['Qualifications']]))\n",
        "\n",
        "user_sequences = tokenizer.texts_to_sequences(user_df['Skills'])\n",
        "event_sequences = tokenizer.texts_to_sequences(event_df['Qualifications'])\n",
        "\n",
        "# Pad the sequences\n",
        "user_data = pad_sequences(user_sequences)\n",
        "event_data = pad_sequences(event_sequences)\n",
        "\n",
        "# Define the model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 50\n",
        "num_filters = 10\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=user_data.shape[1]),\n",
        "    Conv1D(num_filters, kernel_size, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(user_data, np.ones(len(user_data)), epochs=5, verbose=1)\n",
        "\n",
        "# Compute recommendations\n",
        "user_embeddings = model.get_layer(index=0).get_weights()[0]\n",
        "event_embeddings = model.get_layer(index=0).get_weights()[0]\n",
        "\n",
        "def recommend_events(user_id, num_recommendations=5):\n",
        "    user_embedding = user_embeddings[user_id]\n",
        "    similarities = np.dot(event_embeddings, user_embedding)\n",
        "    event_ids = np.argsort(-similarities)[:num_recommendations]\n",
        "    return event_df['Event_id'].iloc[event_ids]\n",
        "\n",
        "# Test the recommendation system\n",
        "# print(recommend_events(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkyfhL3kkK4D",
        "outputId": "6fa7d0e2-c73d-4257-efa7-a1519230deac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "88/88 [==============================] - 5s 36ms/step - loss: 0.1595\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 8.7756e-05\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 8.6267e-06\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 2.6305e-06\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 9.1196e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the recommendation system\n",
        "print(recommend_events(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmsXv6nXkVQl",
        "outputId": "b52e6f9f-0360-4a28-ef79-a6a7e7efdb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1     E_2,Youth Development,Jakarta,>18,\"Mentoring, ...\n",
            "9     E_10,Youth Development,\"Maluku, Banda Neira\",1...\n",
            "29                                                 E_30\n",
            "73                                                 E_74\n",
            "49    E_50,Youth Development,Bandung,>20,\"Team build...\n",
            "Name: Event_id, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load your datasets\n",
        "events = pd.read_csv('events_dataset.csv')\n",
        "users = pd.read_csv('users_dataset.csv')\n",
        "\n",
        "# Preprocessing\n",
        "events['Qualifications'] = events['Qualifications'].apply(lambda x: ' '.join(x.lower().split(',')) if pd.notnull(x) else '')\n",
        "users['Skills'] = users['Skills'].apply(lambda x: ' '.join(x.lower().split(','))if pd.notnull(x) else '')\n",
        "\n",
        "# Vectorize the qualifications and skills\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "events_matrix = vectorizer.fit_transform(events['Qualifications'])\n",
        "users_matrix = vectorizer.transform(users['Skills'])\n",
        "\n",
        "# Compute the cosine similarity\n",
        "cosine_sim = cosine_similarity(users_matrix, events_matrix)\n",
        "\n",
        "# Convert the cosine similarity matrix to a DataFrame\n",
        "cosine_sim_df = pd.DataFrame(cosine_sim, columns=events['Event_id'], index=users['Volunteer Name'])\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(cosine_sim_df.columns)]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "target = users['Volunteer Name']\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "\n",
        "# Train the model\n",
        "model.fit(cosine_sim_df,target ,epochs=10)\n"
      ],
      "metadata": {
        "id": "Fksenmb2SA-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2_r80-AkGh2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚õπ"
      ],
      "metadata": {
        "id": "hWvLxj-_Giw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using One Hot and Tokenizer üâê\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "paFumD-IGw2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load Event dataset\n",
        "event_data = pd.read_csv(\"./events_dataset.csv\",usecols=['Event_id','Category','Location','Qualifications'])\n",
        "event_df = pd.DataFrame(event_data,)\n",
        "\n",
        "# Load User dataset\n",
        "user_data = pd.read_csv(\"./users_data_interest.csv\",usecols=['Volunteer Name','Skills','Location','Type of Organization','Interest'])\n",
        "user_df = pd.DataFrame(user_data)\n",
        "\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n",
        "\n",
        "# Split event and user data into training and testing sets\n",
        "event_train, event_test = train_test_split(event_df, test_size=0.2, random_state=42)\n",
        "user_train, user_test = train_test_split(user_df, test_size=0.2, random_state=42)\n",
        "y_train, y_test = train_test_split(user_df['Interest'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenizer Train and Test Qualifications\n",
        "tokenizer_qualification = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer_qualification.fit_on_texts(event_train['Qualifications'])\n",
        "\n",
        "qualification_seq = tokenizer_qualification.texts_to_sequences(event_train['Qualifications'])\n",
        "qualification_pad = pad_sequences(qualification_seq, maxlen=max_length, padding=padding_type, truncating= trunc_type)\n",
        "\n",
        "qualification_seq_test = tokenizer_qualification.texts_to_sequences(event_test['Qualifications'])\n",
        "qualification_pad_test = pad_sequences(qualification_seq_test, maxlen=max_length, padding=padding_type, truncating= trunc_type)\n",
        "\n",
        "# Tokenizer Train and Test Skill\n",
        "tokenizer_skill = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer_skill.fit_on_texts(user_train['Skills'])\n",
        "\n",
        "skill_seq = tokenizer_skill.texts_to_sequences(user_train['Skills'])\n",
        "skill_pad = pad_sequences(skill_seq, maxlen=max_length, padding=padding_type, truncating= trunc_type)\n",
        "\n",
        "skill_seq_test = tokenizer_skill.texts_to_sequences(user_test['Skills'])\n",
        "skill_pad_test = pad_sequences(skill_seq_test, maxlen=max_length, padding=padding_type, truncating= trunc_type)\n",
        "\n",
        "# One hot encoding Event\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "event_cat_loc_org_encoded_train = encoder.fit_transform(event_train[['Category', 'Location']])\n",
        "event_cat_loc_org_encoded_test = encoder.transform(event_test[['Category', 'Location']])\n",
        "\n",
        "# One hot encoding user\n",
        "user_loc_org_encoded_train = encoder.fit_transform(user_train[['Location', 'Type of Organization']])\n",
        "user_loc_org_encoded_test = encoder.transform(user_test[['Location', 'Type of Organization']])\n",
        "\n",
        "\n",
        "# Build user model\n",
        "user_NN = tf.keras.models.Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, name='user_embedding')  # output layer for user model\n",
        "])\n",
        "\n",
        "# Build event model\n",
        "event_NN = tf.keras.models.Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, name='event_embedding')  # output layer for event model\n",
        "])\n",
        "\n",
        "# Inputs for user and event\n",
        "input_user_skills = Input(shape=(max_length,), name='input_user_skills')\n",
        "input_user_loc_org = Input(shape=(user_loc_org_encoded_train.shape[1],), name='input_user_loc_org')\n",
        "input_event_qualifications = Input(shape=(max_length,), name='input_event_qualifications')\n",
        "input_event_cat_loc_org = Input(shape=(event_cat_loc_org_encoded_train.shape[1],), name='input_event_cat_loc_org')\n",
        "\n",
        "# Call user and event models\n",
        "vu_skills = user_NN(input_user_skills)\n",
        "vu_loc_org = Dense(128, activation='relu')(input_user_loc_org)\n",
        "vu = Concatenate()([vu_skills, vu_loc_org])\n",
        "\n",
        "vm_qualifications = event_NN(input_event_qualifications)\n",
        "vm_cat_loc_org = Dense(128, activation='relu')(input_event_cat_loc_org)\n",
        "vm = Concatenate()([vm_qualifications, vm_cat_loc_org])\n",
        "\n",
        "combined_vu_vm = Concatenate()([vu, vm])\n",
        "\n",
        "# Specify the inputs and outputs of the model\n",
        "# model = tf.keras.Model([input_user_skills, input_user_loc_org, input_event_qualifications, input_event_cat_loc_org], [vu, vm])\n",
        "\n",
        "# test with combined\n",
        "model = Model([input_user_skills, input_user_loc_org, input_event_qualifications, input_event_cat_loc_org],combined_vu_vm)\n"
      ],
      "metadata": {
        "id": "z9x7Hp1NGhmo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjvA6Xaj_S31",
        "outputId": "23ee8957-d9d1-4130-b17b-24faf430aab8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_user_skills (InputLa  [(None, 120)]                0         []                            \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " input_user_loc_org (InputL  [(None, 97)]                 0         []                            \n",
            " ayer)                                                                                            \n",
            "                                                                                                  \n",
            " input_event_qualifications  [(None, 120)]                0         []                            \n",
            "  (InputLayer)                                                                                    \n",
            "                                                                                                  \n",
            " input_event_cat_loc_org (I  [(None, 23)]                 0         []                            \n",
            " nputLayer)                                                                                       \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, 64)                   531904    ['input_user_skills[0][0]']   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 128)                  12544     ['input_user_loc_org[0][0]']  \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)   (None, 64)                   531904    ['input_event_qualifications[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 128)                  3072      ['input_event_cat_loc_org[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 192)                  0         ['sequential[0][0]',          \n",
            "                                                                     'dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 192)                  0         ['sequential_1[0][0]',        \n",
            " )                                                                   'dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 384)                  0         ['concatenate[0][0]',         \n",
            " )                                                                   'concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1079424 (4.12 MB)\n",
            "Trainable params: 1079424 (4.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define inputs and outputs for training\n",
        "train_inputs = [skill_pad, user_loc_org_encoded_train, qualification_pad, event_cat_loc_org_encoded_train]"
      ],
      "metadata": {
        "id": "JvMxhXAJALR0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_inputs, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xWh8xD6DTpH",
        "outputId": "0a91482f-d5b6-43a2-a927-0fceb583296a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "70/70 [==============================] - 15s 164ms/step - loss: 0.5609\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.3605\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.2075\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.1152\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0625\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.0333\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0179\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0100\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0060\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e543a313b50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs = [skill_pad_test, user_loc_org_encoded_test, qualification_pad_test, event_cat_loc_org_encoded_test]\n",
        "model.evaluate(test_inputs, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAKgHtoECIul",
        "outputId": "86b70218-befd-430c-a44c-b0ded5155b83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0033\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003309612860903144"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## using the user in the test set\n",
        "user_index = 0\n",
        "user_input = [\n",
        "    skill_pad_test[user_index][None, ...],\n",
        "    user_loc_org_encoded_test[user_index][None, ...],\n",
        "    qualification_pad_test[user_index][None, ...],\n",
        "    event_cat_loc_org_encoded_test[user_index][None, ...],\n",
        "]"
      ],
      "metadata": {
        "id": "LYpTgZ0hFZCr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langsung menggunakan predict"
      ],
      "metadata": {
        "id": "B33W48YVptxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_predictions = model.predict(user_input)\n",
        "\n",
        "# Change prediksi menjadi DataFrame\n",
        "predictions_df = pd.DataFrame(user_predictions.flatten(), columns=['Interest_Score'])\n",
        "\n",
        "# Gabungkan prediksi dengan data event\n",
        "results_df = pd.concat([event_test.reset_index(drop=True), predictions_df], axis=1)\n",
        "\n",
        "# sort event berdasarkan 'Interest_Score'\n",
        "results_df = results_df.sort_values(by='Interest_Score', ascending=False)\n",
        "\n",
        "# Tampilkan 5 rekomendasi tertinggi\n",
        "top_5_recommendations = results_df.head(5)\n",
        "top_5_recommendations\n"
      ],
      "metadata": {
        "id": "Ono5c0ggoq4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lalu ini menggunakan pembobotan terhadap category event dan type of organization user"
      ],
      "metadata": {
        "id": "2lhbGUyVp8-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat prediksi dengan model Anda\n",
        "user_predictions = model.predict(user_input)\n",
        "\n",
        "# Ubah prediksi menjadi DataFrame\n",
        "predictions_df = pd.DataFrame(user_predictions.flatten(), columns=['Interest_Score'])\n",
        "\n",
        "# Gabungkan prediksi dengan data acara\n",
        "results_df = pd.concat([event_test.reset_index(drop=True), predictions_df], axis=1)\n"
      ],
      "metadata": {
        "id": "hoCedBhRWHEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f428275-0a30-4007-cc88-064819343e4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 118ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# add nama pengguna dan 'Type of Organization' ke DataFrame hasil\n",
        "results_df['User_Name'] = user_test.iloc[user_index]['Volunteer Name']\n",
        "results_df['User_Organization_Type'] = user_test.iloc[user_index]['Type of Organization']\n",
        "\n",
        "# kolom baru 'Interest_Score_Adjusted' yang memberikan bobot lebih tinggi\n",
        "# untuk acara yang 'Category'-nya cocok dengan 'Type of Organization' pengguna\n",
        "results_df['Interest_Score_Adjusted'] = np.where(results_df['Category'] == results_df['User_Organization_Type'],\n",
        "                                                 results_df['Interest_Score'] * 1.2,\n",
        "                                                 results_df['Interest_Score'])\n",
        "\n",
        "# Urutkan acara berdasarkan 'Interest_Score_Adjusted' dalam urutan menurun\n",
        "results_df = results_df.sort_values(by='Interest_Score_Adjusted', ascending=False)\n",
        "\n",
        "# Tampilkan 5 rekomendasi tertinggi\n",
        "top_5_recommendations = results_df.head(5)\n",
        "top_5_recommendations"
      ],
      "metadata": {
        "id": "LnGT0QaqtaBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_test.columns\n",
        "user_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Dzf3A64xaljN",
        "outputId": "c01c15bc-4eef-429b-ac6b-b6631d4499d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Volunteer Name                                             Skills  \\\n",
              "2078   Ethan Walker               Environmental activism, Conservation   \n",
              "2770   James Cooper               Veterinary assistance, Animal rescue   \n",
              "1465   Amelia Adams                            Nursing, Geriatric care   \n",
              "2089  Liam Thompson                Teaching, English language tutoring   \n",
              "2118    Emily Davis  Animal shelter volunteering, Pet adoption support   \n",
              "\n",
              "          Location    Type of Organization  Interest  \n",
              "2078        Serang           Environmental         1  \n",
              "2770  Lubuklinggau              Healthcare         1  \n",
              "1465      Bengkulu       Youth Development         1  \n",
              "2089     Palembang                  Social         1  \n",
              "2118        Binjai  Pet and Animal Service         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee885dfc-ece1-4914-aec0-81c32d62aed4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Volunteer Name</th>\n",
              "      <th>Skills</th>\n",
              "      <th>Location</th>\n",
              "      <th>Type of Organization</th>\n",
              "      <th>Interest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2078</th>\n",
              "      <td>Ethan Walker</td>\n",
              "      <td>Environmental activism, Conservation</td>\n",
              "      <td>Serang</td>\n",
              "      <td>Environmental</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2770</th>\n",
              "      <td>James Cooper</td>\n",
              "      <td>Veterinary assistance, Animal rescue</td>\n",
              "      <td>Lubuklinggau</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1465</th>\n",
              "      <td>Amelia Adams</td>\n",
              "      <td>Nursing, Geriatric care</td>\n",
              "      <td>Bengkulu</td>\n",
              "      <td>Youth Development</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2089</th>\n",
              "      <td>Liam Thompson</td>\n",
              "      <td>Teaching, English language tutoring</td>\n",
              "      <td>Palembang</td>\n",
              "      <td>Social</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2118</th>\n",
              "      <td>Emily Davis</td>\n",
              "      <td>Animal shelter volunteering, Pet adoption support</td>\n",
              "      <td>Binjai</td>\n",
              "      <td>Pet and Animal Service</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee885dfc-ece1-4914-aec0-81c32d62aed4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee885dfc-ece1-4914-aec0-81c32d62aed4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee885dfc-ece1-4914-aec0-81c32d62aed4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-91369c88-a630-43ea-8f9e-c884d8b2de32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91369c88-a630-43ea-8f9e-c884d8b2de32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-91369c88-a630-43ea-8f9e-c884d8b2de32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_at_index_one = user_test.loc[user_test.index[0], 'Volunteer Name']\n",
        "print(\"Name at index one:\", name_at_index_one)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvnZLTpvWAiW",
        "outputId": "781f97e1-47e1-44b3-a417-ab30e54eb4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name at index one: Ethan Walker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# GIST Code\n",
        "```\n",
        "This to make predict, but not use bobot to category\n",
        "# Make predictions for the user\n",
        "user_predictions = model.predict(user_input)\n",
        "\n",
        "# Extract event IDs from the test set\n",
        "event_ids = event_test['Event_id'].values\n",
        "\n",
        "# Flatten user_predictions and event_ids\n",
        "user_predictions_flat = user_predictions.flatten()\n",
        "event_ids_flat = event_ids[:user_predictions_flat.shape[0]]\n",
        "\n",
        "user_predictions_flat.shape, event_ids_flat.shape\n",
        "\n",
        "\n",
        "print(\"Length of event_ids:\", len(event_ids))\n",
        "print(\"Length of user_predictions:\", len(user_predictions.flatten()))\n",
        "print(\"Shape of user_predictions:\", user_predictions.shape)\n",
        "print(\"Number of unique event_ids:\", len(event_test['Event_id'].unique()))\n",
        "\n",
        "\n",
        "# Ambil informasi kategori dan kualifikasi dari dataset event_test\n",
        "event_info_selected = event_test[event_test['Event_id'].isin(event_ids_flat)][['Event_id', 'Category', 'Qualifications']]\n",
        "\n",
        "# Gabungkan hasil prediksi dan informasi event\n",
        "results_df = pd.DataFrame({\n",
        "    'Event_id': event_ids_flat,\n",
        "    'Interest_Score': user_predictions_flat\n",
        "})\n",
        "\n",
        "# Gabungkan dengan informasi kategori dan kualifikasi\n",
        "results_df = pd.merge(results_df, event_info_selected, on='Event_id')\n",
        "\n",
        "# Sort events based on predicted interest scores in descending order\n",
        "recommendations = results_df.sort_values(by='Interest_Score', ascending=False)\n",
        "\n",
        "# Display the top N recommendations\n",
        "top_n_recommendations = 5\n",
        "top_recommendations = recommendations.head(top_n_recommendations)\n",
        "\n",
        "print(f\"Top {top_n_recommendations} recommendations for the user:\")\n",
        "# print(top_recommendations[['Event_id', 'Category', 'Qualifications', 'Interest_Score']])\n",
        "top_recommendations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Shape of user_predictions before flatten:\", user_predictions.shape)\n",
        "print(\"Length of event_ids:\", len(event_ids))\n",
        "\n",
        "# Flatten user_predictions\n",
        "user_predictions_flat = user_predictions.flatten()\n",
        "\n",
        "print(\"Shape of user_predictions after flatten:\", user_predictions_flat.shape)\n",
        "print(\"Length of event_ids after adjustment:\", len(event_ids[:user_predictions_flat.shape[0]]))\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "t4RIZa0Teg81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Trying use 2 condition skill=qualification and category=type of organization\n",
        "```\n",
        "\n",
        "results_df['User_Skills'] = user_test.iloc[user_index]['Skills']\n",
        "results_df['Event_Qualifications'] = event_test.iloc[user_index]['Qualifications']\n",
        "\n",
        "results_df['Skill_Qualification_Match'] = results_df.apply(lambda row: 1 if row['User_Skills'] in row['Event_Qualifications'] else 0, axis=1)\n",
        "\n",
        "results_df['Category_Organization_Match'] = np.where(results_df['Category'] == results_df['User_Organization_Type'], 1, 0)\n",
        "\n",
        "results_df['Interest_Score_Adjusted'] = np.where(results_df['Skill_Qualification_Match'] == 1,\n",
        "                                                 results_df['Interest_Score'] * 1.1,\n",
        "                                                 results_df['Interest_Score'])\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "iuLCLVXxm6J3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===========================================\n",
        "\n",
        "# Breakline\n"
      ],
      "metadata": {
        "id": "loAtapYJNfW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# This one if there is already have interact user to event\n",
        "Jadi make dot.\n",
        "```\n",
        "## Inputs for user and event\n",
        "# input_user_skills = Input(shape=(max_length,), name='input_user_skills')\n",
        "# input_user_loc_org = Input(shape=(user_loc_org_encoded_train.shape[1],), name='input_user_loc_org')\n",
        "# input_event_qualifications = Input(shape=(max_length,), name='input_event_qualifications')\n",
        "# input_event_cat_loc_org = Input(shape=(event_cat_loc_org_encoded_train.shape[1],), name='input_event_cat_loc_org')\n",
        "\n",
        "\n",
        "## Call user and event models\n",
        "# vu_skills = user_NN(input_user_skills)\n",
        "# vu_loc_org = Dense(128, activation='relu')(input_user_loc_org)\n",
        "# vu = Concatenate()([vu_skills, vu_loc_org])\n",
        "\n",
        "# vm_qualifications = event_NN(input_event_qualifications)\n",
        "# vm_cat_loc_org = Dense(128, activation='relu')(input_event_cat_loc_org)\n",
        "# vm = Concatenate()([vm_qualifications, vm_cat_loc_org])\n",
        "\n",
        "# Compute the dot product of the two vectors vu and vm\n",
        "# output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
        "\n",
        "# Specify the inputs and output of the model\n",
        "# model = tf.keras.Model([input_user_skills, input_user_loc_org, input_event_qualifications, input_event_cat_loc_org], output)\n",
        "# model.summary()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Gy524NdiDUvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXCHA93nDT3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B5r04evRDUDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another one"
      ],
      "metadata": {
        "id": "OFXu7y-PDX9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load Event dataset\n",
        "event_data = pd.read_csv(\"./events_dataset.csv\",usecols=['Event_id','Category','Location','Qualifications'])\n",
        "event_df = pd.DataFrame(event_data,)\n",
        "\n",
        "# Load User dataset\n",
        "user_data = pd.read_csv(\"./users_dataset.csv\",usecols=['Volunteer Name','Skills','Location','Type of Organization'])\n",
        "user_df = pd.DataFrame(user_data)\n",
        "\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n",
        "\n",
        "# Split event and user data into training and testing sets\n",
        "event_train, event_test = train_test_split(event_df, test_size=0.2, random_state=42)\n",
        "user_train, user_test = train_test_split(user_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenizer Train and Test Qualifications\n",
        "tokenizer_qualification = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer_qualification.fit_on_texts(event_train['Qualifications'])\n",
        "\n",
        "qualification_seq = tokenizer_qualification.texts_to_sequences(event_train['Qualifications'])\n",
        "qualification_pad = pad_sequences(qualification_seq, maxlen=max_length, padding=padding_type, truncating= trunc_type)\n",
        "\n",
        "qualification_seq_test = tokenizer_qualification.texts_to_sequences(event_test['Qualifications'])\n",
        "qualification_pad_test = pad_sequences(qualification_seq_test, maxlen=max_length, padding=padding_type, truncating= trunc_type)\n",
        "\n",
        "# Tokenizer Train and Test Skill\n",
        "tokenizer_skill = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer_skill.fit_on_texts(user_train['Skills'])\n",
        "\n",
        "skill_seq = tokenizer_skill.texts_to_sequences(user_train['Skills'])\n",
        "skill_pad = pad_sequences(skill_seq, maxlen=max_length, padding=padding_type, truncating= trunc_type)\n",
        "\n",
        "skill_seq_test = tokenizer_skill.texts_to_sequences(user_test['Skills'])\n",
        "skill_pad_test = pad_sequences(skill_seq_test, maxlen=max_length, padding=padding_type, truncating= trunc_type)\n",
        "\n",
        "# One hot encoding Event\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "event_cat_loc_org_encoded_train = encoder.fit_transform(event_train[['Category', 'Location']])\n",
        "event_cat_loc_org_encoded_test = encoder.transform(event_test[['Category', 'Location']])\n",
        "\n",
        "# One hot encoding user\n",
        "user_loc_org_encoded_train = encoder.fit_transform(user_train[['Location', 'Type of Organization']])\n",
        "user_loc_org_encoded_test = encoder.transform(user_test[['Location', 'Type of Organization']])\n",
        "\n",
        "# User model\n",
        "input_user_skills = Input(shape=(max_length,), name='input_user_skills')\n",
        "x = Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length)(input_user_skills)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "vu_skills = Dense(64, name='user_embedding')(x)\n",
        "x = Dense(128, activation='relu')(vu_skills)\n",
        "output_user_skills = Dense(max_length, activation='sigmoid')(x)\n",
        "user_NN = tf.keras.Model(input_user_skills, output_user_skills)\n",
        "\n",
        "# Event model\n",
        "input_event_qualifications = Input(shape=(max_length,), name='input_event_qualifications')\n",
        "x = Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length)(input_event_qualifications)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "vm_qualifications = Dense(64, name='event_embedding')(x)\n",
        "x = Dense(128, activation='relu')(vm_qualifications)\n",
        "output_event_qualifications = Dense(max_length, activation='sigmoid')(x)\n",
        "event_NN = tf.keras.Model(input_event_qualifications, output_event_qualifications)\n",
        "\n",
        "# Compile the models\n",
        "user_NN.compile(optimizer='adam', loss='mean_squared_error')\n",
        "event_NN.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FWMmpqMMAg5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the models\n",
        "user_NN.fit(skill_pad, skill_pad, epochs=10, verbose=1)\n",
        "event_NN.fit(qualification_pad, qualification_pad, epochs=10, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BdW16aFDA18",
        "outputId": "a030dc95-e6f1-4982-c84d-08ae1d478eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "70/70 [==============================] - 7s 36ms/step - loss: 60.3635\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 1s 19ms/step - loss: 60.2221\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 60.2222\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 60.2214\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 60.2173\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 60.2160\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 60.2159\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 60.2159\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 60.2159\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 60.2159\n",
            "Epoch 1/10\n",
            "70/70 [==============================] - 4s 27ms/step - loss: 72.1766\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 1s 11ms/step - loss: 71.9486\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 1s 6ms/step - loss: 71.9486\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 71.9486\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 71.9486\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 71.9486\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 71.9486\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 71.9486\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 71.9485\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 71.9483\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f93b01403d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Generate embeddings for users and events\n",
        "user_embeddings = user_NN.predict(skill_pad)\n",
        "event_embeddings = event_NN.predict(qualification_pad)\n",
        "\n",
        "# Select a specific user\n",
        "user_index = 2  # replace this with the index of the user\n",
        "user_embedding = user_embeddings[user_index]\n",
        "\n",
        "# Compute similarity scores for the selected user and all events\n",
        "similarity_scores = cosine_similarity(user_embedding.reshape(1, -1), event_embeddings)\n",
        "\n",
        "\n",
        "# Get the indices of the events that have the highest similarity scores\n",
        "top_event_indices = np.argsort(similarity_scores[0])[::-1]\n",
        "\n",
        "# Select the top 10 events\n",
        "top_10_event_indices = top_event_indices[:10]\n",
        "top_10 = event_df.iloc[top_10_event_indices]\n",
        "\n",
        "print(\"Top 10 event indices:\")\n",
        "top_10\n",
        "\n"
      ],
      "metadata": {
        "id": "oParBOFwIBG9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "f3605b1c-f509-49c3-89af-ab565d441503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 0s 2ms/step\n",
            "70/70 [==============================] - 0s 2ms/step\n",
            "Top 10 event indices:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Event_id           Category             Location  \\\n",
              "0          E1  Youth Development                 Solo   \n",
              "512      E513                 IT              Jakarta   \n",
              "1250    E1251         Healthcare           Yogyakarta   \n",
              "1251    E1252         Healthcare              Jakarta   \n",
              "509      E510                 IT              Jakarta   \n",
              "1253    E1254         Healthcare           Yogyakarta   \n",
              "506      E507                 IT              Bandung   \n",
              "505      E506                 IT           Jawa Barat   \n",
              "1256    E1257         Healthcare  Maluku, Banda Neira   \n",
              "504      E505                 IT            Tangerang   \n",
              "\n",
              "                                         Qualifications  \n",
              "0                    Youth mentoring, Youth empowerment  \n",
              "512                  Computer literacy, Web development  \n",
              "1250               Nutrition, Lab assistance, First aid  \n",
              "1251  Medical assistance, Lab assistance, Lab techni...  \n",
              "509   Data analysis, Computer literacy, Web development  \n",
              "1253                                            Nursing  \n",
              "506   Graphic design, Computer programming, Data ana...  \n",
              "505                    Customer service, Lab assistance  \n",
              "1256        First aid, Medical research, Lab technician  \n",
              "504               Visual communication, Web development  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e757b41-05ca-45af-a580-32e019122e70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Event_id</th>\n",
              "      <th>Category</th>\n",
              "      <th>Location</th>\n",
              "      <th>Qualifications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E1</td>\n",
              "      <td>Youth Development</td>\n",
              "      <td>Solo</td>\n",
              "      <td>Youth mentoring, Youth empowerment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>E513</td>\n",
              "      <td>IT</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>Computer literacy, Web development</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1250</th>\n",
              "      <td>E1251</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Yogyakarta</td>\n",
              "      <td>Nutrition, Lab assistance, First aid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>E1252</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>Medical assistance, Lab assistance, Lab techni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>E510</td>\n",
              "      <td>IT</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>Data analysis, Computer literacy, Web development</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>E1254</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Yogyakarta</td>\n",
              "      <td>Nursing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>E507</td>\n",
              "      <td>IT</td>\n",
              "      <td>Bandung</td>\n",
              "      <td>Graphic design, Computer programming, Data ana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>E506</td>\n",
              "      <td>IT</td>\n",
              "      <td>Jawa Barat</td>\n",
              "      <td>Customer service, Lab assistance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>E1257</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Maluku, Banda Neira</td>\n",
              "      <td>First aid, Medical research, Lab technician</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>E505</td>\n",
              "      <td>IT</td>\n",
              "      <td>Tangerang</td>\n",
              "      <td>Visual communication, Web development</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e757b41-05ca-45af-a580-32e019122e70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e757b41-05ca-45af-a580-32e019122e70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e757b41-05ca-45af-a580-32e019122e70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-20565dc5-45df-4d0e-8233-ec9fae0c5674\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20565dc5-45df-4d0e-8233-ec9fae0c5674')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-20565dc5-45df-4d0e-8233-ec9fae0c5674 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tUDz9vvAIMZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-g-ow3AWTtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLkTHES8WUQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_-5tw51PWUM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTTTTTTTTTTTTTTTTTTTT"
      ],
      "metadata": {
        "id": "BONZ_wE3WUwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load Event dataset\n",
        "event_data = pd.read_csv(\"./events_dataset.csv\", usecols=['Event_id', 'Category', 'Location', 'Qualifications'])\n",
        "event_df = pd.DataFrame(event_data)\n",
        "\n",
        "# Load User dataset\n",
        "user_data = pd.read_csv(\"./users_dataset.csv\", usecols=['Volunteer Name', 'Skills', 'Location', 'Type of Organization'])\n",
        "user_df = pd.DataFrame(user_data)\n",
        "\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n",
        "\n",
        "# Tokenizer for Event Categories\n",
        "tokenizer_category = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer_category.fit_on_texts(event_df['Category'])\n",
        "category_seq = tokenizer_category.texts_to_sequences(event_df['Category'])\n",
        "category_pad = pad_sequences(category_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Tokenizer for Event Qualifications\n",
        "tokenizer_qualification = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer_qualification.fit_on_texts(event_df['Qualifications'])\n",
        "qualification_seq = tokenizer_qualification.texts_to_sequences(event_df['Qualifications'])\n",
        "qualification_pad = pad_sequences(qualification_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Tokenizer for User Skills\n",
        "tokenizer_skill = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer_skill.fit_on_texts(user_df['Skills'])\n",
        "skill_seq = tokenizer_skill.texts_to_sequences(user_df['Skills'])\n",
        "skill_pad = pad_sequences(skill_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Combine all features into a single matrix for both events and users\n",
        "event_features = np.hstack((category_pad, qualification_pad))\n",
        "user_features = skill_pad\n",
        "\n",
        "# Build a simple content-based recommendation model\n",
        "input_event_user = Concatenate()([Input(shape=(max_length,), name='input_event_category'),\n",
        "                                   Input(shape=(max_length,), name='input_event_qualifications'),\n",
        "                                   Input(shape=(max_length,), name='input_user_skills')])\n",
        "\n",
        "x = Dense(128, activation='relu')(input_event_user)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output_recommendation = Dense(max_length, activation='sigmoid')(x)\n",
        "\n",
        "content_based_model = Model(inputs=input_event_user,\n",
        "                            outputs=output_recommendation)\n",
        "\n",
        "# Compile the model\n",
        "content_based_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "print(category_pad.shape)\n",
        "print(qualification_pad.shape)\n",
        "print(skill_pad.shape)\n",
        "print(user_loc_org_encoded_train.shape)\n",
        "\n",
        "# Train the model\n",
        "# content_based_model.fit([category_pad, qualification_pad, skill_pad], user_loc_org_encoded_train, epochs=10, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "oNwuwO4FWWQT",
        "outputId": "e7dbdbc8-4010-42d9-962e-48ef33f7ee04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2786, 120)\n",
            "(2786, 120)\n",
            "(2786, 120)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-47b0c1aa8d71>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualification_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_loc_org_encoded_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'user_loc_org_encoded_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwC9nIO_W3Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load Event dataset\n",
        "event_data = pd.read_csv(\"./events_dataset.csv\", usecols=['Event_id', 'Category', 'Location', 'Qualifications'])\n",
        "event_df = pd.DataFrame(event_data)\n",
        "\n",
        "# Load User dataset\n",
        "user_data = pd.read_csv(\"./users_dataset.csv\", usecols=['Volunteer Name', 'Skills', 'Location', 'Type of Organization'])\n",
        "user_df = pd.DataFrame(user_data)\n",
        "\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n",
        "\n",
        "# Split event and user data into training and testing sets\n",
        "event_train, event_test = train_test_split(event_df, test_size=0.2, random_state=42)\n",
        "user_train, user_test = train_test_split(user_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenizer Train and Test Qualifications\n",
        "tokenizer_qualification = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer_qualification.fit_on_texts(event_train['Qualifications'])\n",
        "\n",
        "qualification_seq = tokenizer_qualification.texts_to_sequences(event_train['Qualifications'])\n",
        "qualification_pad = pad_sequences(qualification_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "qualification_seq_test = tokenizer_qualification.texts_to_sequences(event_test['Qualifications'])\n",
        "qualification_pad_test = pad_sequences(qualification_seq_test, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Tokenizer Train and Test Skill\n",
        "tokenizer_skill = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer_skill.fit_on_texts(user_train['Skills'])\n",
        "\n",
        "skill_seq = tokenizer_skill.texts_to_sequences(user_train['Skills'])\n",
        "skill_pad = pad_sequences(skill_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "skill_seq_test = tokenizer_skill.texts_to_sequences(user_test['Skills'])\n",
        "skill_pad_test = pad_sequences(skill_seq_test, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Create labels for classification (1 for positive match, 0 for no match)\n",
        "labels_train = np.ones(len(user_train))\n",
        "labels_test = np.ones(len(user_test))\n",
        "\n",
        "# User model\n",
        "input_user_skills = Input(shape=(max_length,), name='input_user_skills')\n",
        "x = Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length)(input_user_skills)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "vu_skills = Dense(64, name='user_embedding')(x)\n",
        "x = Dense(128, activation='relu')(vu_skills)\n",
        "output_user_skills = Dense(1, activation='sigmoid')(x)\n",
        "user_NN = Model(inputs=input_user_skills, outputs=output_user_skills)\n",
        "\n",
        "# Event model\n",
        "input_event_qualifications = Input(shape=(max_length,), name='input_event_qualifications')\n",
        "x = Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length)(input_event_qualifications)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "vm_qualifications = Dense(64, name='event_embedding')(x)\n",
        "x = Dense(128, activation='relu')(vm_qualifications)\n",
        "output_event_qualifications = Dense(1, activation='sigmoid')(x)\n",
        "event_NN = Model(inputs=input_event_qualifications, outputs=output_event_qualifications)\n",
        "\n",
        "# Compile the models\n",
        "user_NN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "event_NN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the models\n",
        "user_NN.fit(skill_pad, labels_train, epochs=10, verbose=1)\n",
        "event_NN.fit(qualification_pad, labels_train, epochs=10, verbose=1)\n",
        "\n",
        "# Evaluate the models on the test set\n",
        "user_preds = user_NN.predict(skill_pad_test)\n",
        "event_preds = event_NN.predict(qualification_pad_test)\n",
        "\n",
        "# Convert predictions to binary (1 if prediction > 0.5, else 0)\n",
        "user_preds_binary = (user_preds > 0.5).astype(int)\n",
        "event_preds_binary = (event_preds > 0.5).astype(int)\n",
        "\n",
        "# Compute accuracy on the test set\n",
        "user_accuracy = accuracy_score(labels_test, user_preds_binary)\n",
        "event_accuracy = accuracy_score(labels_test, event_preds_binary)\n",
        "\n",
        "print(f\"User Model Accuracy: {user_accuracy}\")\n",
        "print(f\"Event Model Accuracy: {event_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UriNnrYadeG5",
        "outputId": "d7c7fbae-0b83-41b0-880d-3965cc5ed9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "70/70 [==============================] - 20s 203ms/step - loss: 0.0366 - accuracy: 0.9856\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 3s 41ms/step - loss: 1.8545e-10 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 3s 48ms/step - loss: 1.8338e-10 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 1.8338e-10 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 1s 19ms/step - loss: 1.8338e-10 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 1.8338e-10 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 1s 17ms/step - loss: 1.8338e-10 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 1.8338e-10 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 1.8338e-10 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8338e-10 - accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "70/70 [==============================] - 3s 26ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 5.1735e-12 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 5.1183e-12 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 5.1183e-12 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 5.1183e-12 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 5.1183e-12 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 5.1183e-12 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 5.1183e-12 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 5.1183e-12 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 5.1183e-12 - accuracy: 1.0000\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "18/18 [==============================] - 0s 2ms/step\n",
            "User Model Accuracy: 1.0\n",
            "Event Model Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}