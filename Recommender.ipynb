{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/argalusmp/CH2-PS_Recommendation-System/blob/V/Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Collab](https://colab.research.google.com/drive/1d9l2-NXW5traKPQ0j-l4eZ2vSI0mEVvV)"
      ],
      "metadata": {
        "id": "wY4aTHkiG5bL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Recommendation System with Content-Based Filtering**"
      ],
      "metadata": {
        "id": "l8nhDATdPwXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages\n",
        "\n",
        "Import Packages\n",
        "\n"
      ],
      "metadata": {
        "id": "a5u2dta3QRWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "gqGtDqpdQgiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset\n"
      ],
      "metadata": {
        "id": "-gw06VeaRCOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_dataset = pd.read_csv(\"./users_dataset.csv\")\n",
        "event_dataset= pd.read_csv(\"./events_dataset.csv\")"
      ],
      "metadata": {
        "id": "XUo3-g3uRFqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_user = pd.DataFrame(user_dataset)\n",
        "df_event = pd.DataFrame(event_dataset)"
      ],
      "metadata": {
        "id": "Ro1ezA7xF-c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_user))\n",
        "print(len(df_event))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPlV_6I2TdkE",
        "outputId": "75b14f65-33c6-4b2e-9f25-f7eccfdada38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2786\n",
            "2786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skills_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "skills_encoded = skills_encoder.fit_transform(df_user[['Skills']])"
      ],
      "metadata": {
        "id": "QbCb8aclGZC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "location_encoded = location_encoder.fit_transform(df_event[['Location']])\n"
      ],
      "metadata": {
        "id": "NybQAYiqJWK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding untuk kategori acara\n",
        "category_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "category_encoded = category_encoder.fit_transform(df_event[['Category']])"
      ],
      "metadata": {
        "id": "3eAYvs3MJXLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagi data menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_volunteer[['Skills', 'Location', 'Age']], df_volunteer['Target_Label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "oTkyHVPuJYEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data\n"
      ],
      "metadata": {
        "id": "Z7KBW-TR_mX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.merge(user_dataset, event_dataset, how='cross')"
      ],
      "metadata": {
        "id": "rnNdQnXePd4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pisahkan data menjadi train dan test\n",
        "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Hv5LGlTTPpKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing user data\n",
        "user_dataset['Skills'] = user_dataset['Skills'].str.lower()\n",
        "user_dataset['Availability'] = user_dataset['Availability'].str.lower()\n",
        "user_dataset['Location'] = user_dataset['Location'].str.lower()\n",
        "user_dataset['Type of Organization'] = user_dataset['Type of Organization'].str.lower()\n",
        "\n",
        "## Preprocessing event data\n",
        "event_dataset['Kualifikasi'] = event_dataset['Kualifikasi'].str.lower()\n",
        "event_dataset['Domisili'] = event_dataset['Domisili'].str.lower()\n",
        "event_dataset['Kategori'] = event_dataset['Kategori'].str.lower()\n",
        "event_dataset['Age'] = event_dataset['Age'].str.lower()\n",
        "\n",
        "\n",
        "## Memisahkan user skill menjadi beberapa kolom terpisah untuk one hot\n",
        "user_skills_split = user_dataset['Skills'].str.split(', ', expand=True)\n",
        "\n",
        "## Create one-hot encoding for user skills\n",
        "user_skills_one_hot = pd.get_dummies(user_skills_split, prefix='Skill')"
      ],
      "metadata": {
        "id": "w8v2Jmrc_kVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Menggabungkan dataset\n",
        "merged_data = pd.merge(user_dataset, event_dataset, how='cross')\n",
        "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
        "\n",
        "## Create one-hot encoding for user and event data\n",
        "user_one_hot = pd.get_dummies(merged_data[['Age_x', 'Availability', 'Location', 'Type of Organization']], prefix='User')\n",
        "event_one_hot = pd.get_dummies(merged_data[[ 'Kategori', 'Age_y','Domisili']], prefix='Event')"
      ],
      "metadata": {
        "id": "1TS5IErcJUKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Check Display\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "event_one_hot\n",
        "#user_one_hot"
      ],
      "metadata": {
        "id": "FH_nBWffvpu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Merge Onehot encoding with data user\n",
        "user_data_encode = pd.concat([user_one_hot, user_skills_one_hot], axis=1)\n",
        "user_data_encode"
      ],
      "metadata": {
        "id": "XC8QVVpmc39b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Memisahkan event kualifikasi menjadi beberapa kolom terpisah untuk one hot\n",
        "event_kualifikasi_split = event_dataset['Kualifikasi'].str.split(', ', expand=True)\n",
        "\n",
        "## Create one-hot encoding for kualifikasi\n",
        "event_kualifikasi_one_hot = pd.get_dummies(event_kualifikasi_split, prefix='Kualifikasi')\n",
        "\n",
        "## Merge Kualifikasi with dataset event after one-hot kualifikasi\n",
        "event_data_encode = pd.concat([event_one_hot, event_kualifikasi_one_hot], axis=1)\n"
      ],
      "metadata": {
        "id": "Ckh299YzcEtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Check event encode display\n",
        "event_data_encode"
      ],
      "metadata": {
        "id": "WBS3Q1O7xzlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_data_encode.isnull().sum())\n",
        "print(event_data_encode.isnull().sum())\n"
      ],
      "metadata": {
        "id": "11LOccTgMewM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## For set Y to target\n",
        "#target_columns = ['Kualifikasi_kualifikasi1', 'Kualifikasi_kualifikasi2', ...]\n",
        "#X_train, X_test, y_train, y_test = train_test_split(user_data_encode, event_data_encode[target_columns], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "## Train-test split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HzqxGqliWLJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nyoba proses nilai umur\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "###Pemrosesan Data Umur\n",
        "def process_age(value):\n",
        "    if '-' in str(value):  # Jika nilai adalah rentang umur\n",
        "        age_range = value.split('-')\n",
        "        return (int(age_range[0]) + int(age_range[1])) / 2\n",
        "    elif isinstance(value, int):  # Jika nilai adalah umur tunggal dan sudah integer\n",
        "        return value\n",
        "    else:\n",
        "        # Penanganan lainnya\n",
        "        return None\n",
        "\n",
        "\n",
        "event_dataset['Age'] = event_dataset['Age'].apply(process_age)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "y8lnGwUC_71g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try and Try and Try"
      ],
      "metadata": {
        "id": "PYnicmNlW8VO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pusing NaN"
      ],
      "metadata": {
        "id": "nEbsj81dU3a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Baca dataset\n",
        "user_dataset = pd.read_csv(\"./user_data.csv\")\n",
        "event_dataset = pd.read_csv(\"./event_data.csv\")\n",
        "\n",
        "# Preprocessing user data\n",
        "user_dataset['Skills'] = user_dataset['Skills'].str.lower()\n",
        "user_dataset['Availability'] = user_dataset['Availability'].str.lower()\n",
        "user_dataset['Location'] = user_dataset['Location'].str.lower()\n",
        "user_dataset['Type of Organization'] = user_dataset['Type of Organization'].str.lower()\n",
        "\n",
        "# Preprocessing event data\n",
        "event_dataset['Kualifikasi'] = event_dataset['Kualifikasi'].str.lower()\n",
        "event_dataset['Domisili'] = event_dataset['Domisili'].str.lower()\n",
        "event_dataset['Kategori'] = event_dataset['Kategori'].str.lower()\n",
        "event_dataset['Age'] = event_dataset['Age'].astype(str).str.lower()\n",
        "\n",
        "# Gabungkan data\n",
        "full_data = pd.merge(user_dataset, event_dataset, how='cross')\n",
        "\n",
        "# Pisahkan data menjadi train dan test\n",
        "train_data, test_data = train_test_split(full_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encoding dan penggabungan data\n",
        "user_skills_split = user_dataset['Skills'].str.split(', ', expand=True)\n",
        "user_skills_one_hot = pd.get_dummies(user_skills_split, prefix='Skill')\n",
        "\n",
        "user_one_hot_train = pd.get_dummies(train_data[['Age_x', 'Availability', 'Location', 'Type of Organization']], prefix='User')\n",
        "event_one_hot_train = pd.get_dummies(train_data[['Kategori', 'Age_y', 'Domisili']], prefix='Event')\n",
        "event_kualifikasi_one_hot_train = pd.get_dummies(train_data['Kualifikasi'].str.split(', ', expand=True), prefix='Kualifikasi')\n",
        "\n",
        "train_data_encode = pd.concat([user_one_hot_train, user_skills_one_hot, event_one_hot_train, event_kualifikasi_one_hot_train], axis=1)\n",
        "\n",
        "# Normalisasi data\n",
        "scaler = StandardScaler()\n",
        "train_data_normalize = scaler.fit_transform(train_data_encode)"
      ],
      "metadata": {
        "id": "WXAFNyBjU25g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_normalize = np.nan_to_num(train_data_normalize, nan=np.nanmean(train_data_normalize, axis=0))\n"
      ],
      "metadata": {
        "id": "OCD999T_WEyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.isnan(train_data_normalize).any())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb4H06KBWNn4",
        "outputId": "793a47bb-0821-4018-d651-6964acb0d6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung similarity matrix menggunakan cosine similarity\n",
        "similarity_matrix = cosine_similarity(train_data_normalize, train_data_normalize)"
      ],
      "metadata": {
        "id": "rG_jvJo3VTF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Cosine Similarity: {similarity_matrix[0][0]}\")"
      ],
      "metadata": {
        "id": "e-V7Xo8FWZsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This one using vectorize\n"
      ],
      "metadata": {
        "id": "hmsNhHe3ZkU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "\n",
        "# Load the datasets\n",
        "user_df = pd.read_csv('users_dataset.csv')\n",
        "event_df = pd.read_csv('events_dataset.csv')\n",
        "\n",
        "# Preprocessing\n",
        "user_df['Skills'] = user_df['Skills'].apply(lambda x: ' '.join(x.lower().split(', ')) if pd.notnull(x) else '')\n",
        "event_df['Qualifications'] = event_df['Qualifications'].apply(lambda x: ' '.join(x.lower().split(', ')) if pd.notnull(x) else '')\n",
        "\n",
        "# Vectorize the skills and qualifications\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "user_matrix = vectorizer.fit_transform(user_df['Skills'])\n",
        "event_matrix = vectorizer.transform(event_df['Qualifications'])\n",
        "\n",
        "# Compute the cosine similarity\n",
        "cosine_sim = linear_kernel(user_matrix, event_matrix)\n",
        "\n",
        "# Function to get recommendations\n",
        "def get_recommendations(user_index, cosine_sim=cosine_sim):\n",
        "    # Get the pairwsie similarity scores of all events for that user\n",
        "    sim_scores = list(enumerate(cosine_sim[user_index]))\n",
        "\n",
        "    # Sort the events based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the 10 most similar events\n",
        "    sim_scores = sim_scores[0:10]\n",
        "\n",
        "    # Get the event indices\n",
        "    event_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top 10 most similar events\n",
        "    return event_df['Event_id'].iloc[event_indices]\n",
        "\n",
        "# Test the system relation user 1 (index 0) to event\n",
        "print(get_recommendations(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwIcbYxmW0lV",
        "outputId": "8dfa27fa-d228-495e-eeb7-c01c4fc91e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2592    E_2593\n",
            "2683    E_2684\n",
            "2723    E_2724\n",
            "2735    E_2736\n",
            "2744    E_2745\n",
            "2531    E_2532\n",
            "2659    E_2660\n",
            "2668    E_2669\n",
            "2776    E_2777\n",
            "2399    E_2400\n",
            "Name: Event_id, dtype: object\n"
          ]
        }
      ]
    }
  ]
}